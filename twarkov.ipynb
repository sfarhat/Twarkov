{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from twitter_scraper import get_tweets\n",
    "from twitterscraper import query_tweets\n",
    "import re\n",
    "import datetime as dt\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_info = query_tweets('from:realDonaldTrump', begindate=dt.date(2018,4,11), enddate=dt.date.today())\n",
    "    # def query_tweets(query, limit=None, begindate=dt.date(2017,1,1), enddate=dt.date.today(), poolsize=20, lang=''):\n",
    "    \n",
    "tweets = []\n",
    "for tweet_info in tweets_info:\n",
    "    # text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', tweet.text, flags=re.MULTILINE)\n",
    "    tweet = tweet_info.text\n",
    "    tweets.append(tweet)\n",
    "#     joined_text += tweet.text + ' bbroy '\n",
    "\n",
    "tweets = np.array(tweets)\n",
    "\n",
    "# print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 200\n"
     ]
    }
   ],
   "source": [
    "tweets_info = get_tweets('realDonaldTrump', pages = 10)\n",
    "tweets = []\n",
    "for tweet_info in list(tweets_info):\n",
    "    text = tweet_info['text']\n",
    "    # Add NEWTWEET to help recognize starting word of tweet for future processing\n",
    "    tweets.append(\"NEWTWEET \" + text)\n",
    "    \n",
    "tweets = np.array(tweets)\n",
    "num_tweets = len(tweets)\n",
    "print(\"Number of tweets: \" + str(num_tweets))\n",
    "# print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for tweet in tweets:\n",
    "    words.extend(tweet.split(\" \"))\n",
    "    \n",
    "cleaned_words = []\n",
    "for word in words:\n",
    "    if \".com\" not in word and \"www.\" not in word and \"http\" not in word and word != '':\n",
    "        cleaned_words.append(word)\n",
    "        \n",
    "words = cleaned_words\n",
    "cleaned_words_no_repeat = [words[0]] # could be repeated 'NEWTWEET' due to deleting URL's\n",
    "        \n",
    "for i in range(1, len(words)):\n",
    "    if not (words[i] == \"NEWTWEET\" and words[i] == words[i-1]):\n",
    "        cleaned_words_no_repeat.append(words[i])\n",
    "        \n",
    "words = cleaned_words_no_repeat\n",
    "words = np.array(words)\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "# Initialize states with start and end states (assuming no word is 'S' or 'E')\n",
    "states = ['S', 'E']\n",
    "for word in words:\n",
    "    if word not in states and word != \"\" and word != \"NEWTWEET\":\n",
    "        states.append(word)\n",
    "G.add_nodes_from(states)\n",
    "# nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "edges = []\n",
    "\n",
    "# Edge case for first word in tweet not being connected to Start state\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    if words[i] == \"NEWTWEET\":\n",
    "        edges.append(('S', words[i + 1], 1))\n",
    "        continue\n",
    "    elif words[i+1] == \"NEWTWEET\":\n",
    "        edges.append((words[i], 'E', 1))\n",
    "        continue\n",
    "    elif (words[i], words[i+1]) in freq:\n",
    "        freq[(words[i], words[i+1])] += 1\n",
    "    else:\n",
    "        freq[(words[i], words[i+1])] = 1\n",
    "        \n",
    "    if words[i].endswith(('.', '!', '?')):\n",
    "#         print(words[i], words[i+1])\n",
    "        edges.append((words[i], 'E', 1))\n",
    "        edges.append(('S', words[i + 1], 1))\n",
    "        # remove 'word. Word' so no edge is made between them?\n",
    "        \n",
    "edges.append(('E', 'S', 1))\n",
    "\n",
    "for edge in freq:\n",
    "    edges.append((edge[0], edge[1], freq[edge]))\n",
    "    \n",
    "G.add_weighted_edges_from(edges)\n",
    "# nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(G.successors('S')))\n",
    "# print(list(G.predecessors('E')))\n",
    "\n",
    "# print(list(G.predecessors('S')))\n",
    "# print(list(G.successors('E')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates numpy adjacency matrix of states, where Starting node is row 0 and Ending node is row 1\n",
    "matrix = nx.to_numpy_matrix(G, nodelist = states)\n",
    "matrix = np.array(matrix).tolist()\n",
    "# print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to see if adjacency matrix reflects actual state of MC\n",
    "num = 0\n",
    "for i in range(len(matrix[0])):\n",
    "    num += matrix[0][i]\n",
    "print(num == len(list(G.successors('S'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
