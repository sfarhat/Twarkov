{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from twitter_scraper import get_tweets\n",
    "# from twitterscraper import query_tweets\n",
    "import re\n",
    "import datetime as dt\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person_of_interest = 'realDonaldTrump'\n",
    "# tweets_info = query_tweets('from:' + person_of_interest, begindate=dt.date(2018,4,1), enddate=dt.date.today())\n",
    "# #     # def query_tweets(query, limit=None, begindate=dt.date(2017,1,1), enddate=dt.date.today(), poolsize=20, lang=''):\n",
    "    \n",
    "# # tweets = []\n",
    "# # for tweet_info in tweets_info:\n",
    "# #     tweet = tweet_info.text\n",
    "# #     tweets.append(tweet)\n",
    "\n",
    "# # tweets = np.array(tweets)\n",
    "\n",
    "# # print(tweets)\n",
    "# print(tweets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 201\n"
     ]
    }
   ],
   "source": [
    "tweets_info = get_tweets(person_of_interest, pages = 10)\n",
    "tweets = []\n",
    "for tweet_info in list(tweets_info):\n",
    "    text = tweet_info['text']\n",
    "#     text = tweet_info.text #Figure out which one to use. It does not work consistently yet\n",
    "    # Add NEWTWEET to help recognize starting word of tweet for future processing\n",
    "    tweets.append(\"NEWTWEET \" + text)\n",
    "    \n",
    "tweets.append(\"NEWTWEET\") # Ensures that last word in last tweet is tied to end state\n",
    "    \n",
    "tweets = np.array(tweets)\n",
    "num_tweets = len(tweets)\n",
    "print(\"Number of tweets: \" + str(num_tweets))\n",
    "# print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for tweet in tweets:\n",
    "    words.extend(tweet.split(\" \"))\n",
    "    \n",
    "#edge case of URL attatched to end of sentence without space: ... American families.img.pic.twitter...\n",
    "cleaned_words = []\n",
    "for word in words:\n",
    "    url = [\".com\", \"www.\", \"http\", \"https://\"]\n",
    "    if all(x not in word for x in url) and word != '':\n",
    "#     if \".com\" not in word and \"www.\" not in word and \"http\" not in word and word != '': \n",
    "        cleaned_words.append(word)\n",
    "#     bonuses!pic.twitter.com/0u3dpLJiV2\n",
    "    elif \"pic.\" in word:\n",
    "        index_of_url = word.index(\"pic.\")\n",
    "        cleaned_words.append(word[:index_of_url])\n",
    "        \n",
    "words = cleaned_words\n",
    "cleaned_words_no_repeat = [words[0]] # could be repeated 'NEWTWEET' due to deleting URL's\n",
    "        \n",
    "for i in range(1, len(words)):\n",
    "    if not (words[i] == \"NEWTWEET\" and words[i] == words[i-1]):\n",
    "        cleaned_words_no_repeat.append(words[i])\n",
    "        \n",
    "words = cleaned_words_no_repeat\n",
    "# print(words)\n",
    "# print(words.index(\"and\"))\n",
    "words = np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "# Initialize states with start and end states (assuming no word is 'S' or 'E')\n",
    "states = ['S', 'E']\n",
    "for word in words:\n",
    "    if word not in states and word != \"\" and word != \"NEWTWEET\":\n",
    "        states.append(word)\n",
    "G.add_nodes_from(states)\n",
    "# nx.draw(G, with_labels = True)\n",
    "# print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = {}\n",
    "edges = []\n",
    "\n",
    "# Edge case for first word in tweet not being connected to Start state\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    if words[i] == \"NEWTWEET\":\n",
    "        edges.append(('S', words[i + 1], 1))\n",
    "        continue\n",
    "    elif words[i+1] == \"NEWTWEET\":\n",
    "        edges.append((words[i], 'E', 1))\n",
    "        continue\n",
    "    elif (words[i], words[i+1]) in freq:\n",
    "        freq[(words[i], words[i+1])] += 1\n",
    "    else:\n",
    "        freq[(words[i], words[i+1])] = 1\n",
    "        \n",
    "    if words[i].endswith(('.', '!', '?')):\n",
    "        edges.append((words[i], 'E', 1))\n",
    "        edges.append(('S', words[i + 1], 1))\n",
    "        \n",
    "edges.append(('E', 'S', 1))\n",
    "\n",
    "for edge in freq:\n",
    "    edges.append((edge[0], edge[1], freq[edge]))\n",
    "    \n",
    "G.add_weighted_edges_from(edges)\n",
    "# nx.draw(G, with_labels = True)\n",
    "# nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(list(G.successors('S')))\n",
    "# print(list(G.predecessors('E')))\n",
    "\n",
    "# print(list(G.predecessors('S')))\n",
    "# print(list(G.successors('E')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates numpy adjacency matrix of states, where Starting node is row 0 and Ending node is row 1\n",
    "matrix = nx.to_numpy_matrix(G, nodelist = states)\n",
    "matrix = np.array(matrix).tolist()\n",
    "# print(matrix)\n",
    "# print(np.array(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to see if adjacency matrix reflects actual state of MC\n",
    "num = 0\n",
    "for i in range(len(matrix[0])):\n",
    "    num += matrix[1][i]\n",
    "print(num == len(list(G.successors('E')))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(matrix)):\n",
    "    if np.array(matrix[i]).sum(axis=0) != 0:\n",
    "        continue\n",
    "    else:\n",
    "        print(i, np.array(matrix[i]).sum(axis=0))\n",
    "        print('broken state: ' + states[i])\n",
    "        print(list(G.predecessors(states[i])))\n",
    "\n",
    "matrix = np.delete(matrix, len(matrix)-1, axis=1)\n",
    "matrix = np.delete(matrix, len(matrix)-1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array(matrix)\n",
    "\n",
    "transition_mat = np.array(matrix)/np.array(matrix).sum(axis=1)[:,None]\n",
    "\n",
    "def get_next_state(i, transition_matrix):\n",
    "    return np.random.choice(transition_matrix.shape[1], 1, p=transition_matrix[i])[0]\n",
    "\n",
    "def perform_random_walk(s, e, transition_matrix):\n",
    "    curr_state = s\n",
    "    l = []\n",
    "    while curr_state != e:\n",
    "        curr_state = get_next_state(curr_state, transition_matrix)\n",
    "        if curr_state != s:\n",
    "            l.append(curr_state)\n",
    "    return np.array(l)\n",
    "\n",
    "def generate_sentence():\n",
    "    return ''.join([states[i] + ' ' for i in perform_random_walk(0, 1, transition_mat) if i != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are responsible for hard working American PRIDE! \n"
     ]
    }
   ],
   "source": [
    "tweet = generate_sentence()\n",
    "if tweet.endswith('..'):\n",
    "    tweet += ' ' + generate(sentence)\n",
    "elif tweet.startswith('..'):\n",
    "    tweet = generate_sentence() + ' ' + tweet\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_generation(w1, w2, transition_mat):\n",
    "    \"\"\"\n",
    "    Choose w1, w2 such that they are in the data set\n",
    "    \"\"\"\n",
    "    w1 = states.index(w1)\n",
    "    w2 = states.index(w2)\n",
    "    \n",
    "    mat1 = np.copy(transition_mat)\n",
    "    mat2 = np.copy(transition_mat)\n",
    "    \n",
    "    for i in range(mat1.shape[0]):\n",
    "        mat1[i][w1] += 0.05\n",
    "        mat2[i][w2] += 0.05\n",
    "    \n",
    "    mat1 = mat1/mat1.sum(axis=1)[:,None]\n",
    "    mat2 = mat2/mat2.sum(axis=1)[:,None]\n",
    "    \n",
    "    start = [states[i] + ' ' for i in perform_random_walk(0, w1, mat1) if i != 1]\n",
    "    middle = [states[i] + ' ' for i in perform_random_walk(w1, w2, mat2) if i != 1]\n",
    "    end = [states[i] + ' ' for i in perform_random_walk(w1, 1, transition_mat) if i != 1]\n",
    "    \n",
    "    \n",
    "    return ''.join(start + middle + end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(list(G.predecessors('and')))\n",
    "# print(list(G.successors('and')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Congress must immediately pass a great economic power, is considered a Obama BAD joke. \n"
     ]
    }
   ],
   "source": [
    "tweet = guided_generation(\"Obama\", \"BAD\", transition_mat)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Korea would be WALL last night from China, there was NO WAY. \n"
     ]
    }
   ],
   "source": [
    "tweet = guided_generation(\"Korea\", \"WALL\", transition_mat)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem is that we have been a crime infested & Russia. Obama at the Supreme Court! AUSTIN BOMBING SUSPECT IS DEAD. FBI (why didn’t care. I golf (why didn’t have sought review. \n"
     ]
    }
   ],
   "source": [
    "tweet = guided_generation(\"FBI\", \"golf\", transition_mat)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
