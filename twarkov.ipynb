{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from twitter_scraper import get_tweets\n",
    "from twitterscraper import query_tweets\n",
    "import re\n",
    "import datetime as dt\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person_of_interest = 'realDonaldTrump'\n",
    "# tweets_info = query_tweets('from:' + person_of_interest, begindate=dt.date(2018,4,1), enddate=dt.date.today())\n",
    "# #     # def query_tweets(query, limit=None, begindate=dt.date(2017,1,1), enddate=dt.date.today(), poolsize=20, lang=''):\n",
    "    \n",
    "# # tweets = []\n",
    "# # for tweet_info in tweets_info:\n",
    "# #     tweet = tweet_info.text\n",
    "# #     tweets.append(tweet)\n",
    "\n",
    "# # tweets = np.array(tweets)\n",
    "\n",
    "# # print(tweets)\n",
    "# print(tweets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 201\n"
     ]
    }
   ],
   "source": [
    "tweets_info = get_tweets(person_of_interest, pages = 10)\n",
    "tweets = []\n",
    "for tweet_info in list(tweets_info):\n",
    "    text = tweet_info['text']\n",
    "#     text = tweet_info.text #Figure out which one to use. It does not work consistently yet\n",
    "    # Add NEWTWEET to help recognize starting word of tweet for future processing\n",
    "    tweets.append(\"NEWTWEET \" + text)\n",
    "    \n",
    "tweets.append(\"NEWTWEET\") # Ensures that last word in last tweet is tied to end state\n",
    "    \n",
    "tweets = np.array(tweets)\n",
    "num_tweets = len(tweets)\n",
    "print(\"Number of tweets: \" + str(num_tweets))\n",
    "# print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for tweet in tweets:\n",
    "    words.extend(tweet.split(\" \"))\n",
    "    \n",
    "#edge case of URL attatched to end of sentence without space: ... American families.img.pic.twitter...\n",
    "cleaned_words = []\n",
    "for word in words:\n",
    "    url = [\".com\", \"www.\", \"http\", \"https://\"]\n",
    "    if all(x not in word for x in url) and word != '':\n",
    "#     if \".com\" not in word and \"www.\" not in word and \"http\" not in word and word != '': \n",
    "        cleaned_words.append(word)\n",
    "#     bonuses!pic.twitter.com/0u3dpLJiV2\n",
    "    elif \"pic.\" in word:\n",
    "        index_of_url = word.index(\"pic.\")\n",
    "        cleaned_words.append(word[:index_of_url])\n",
    "        \n",
    "words = cleaned_words\n",
    "cleaned_words_no_repeat = [words[0]] # could be repeated 'NEWTWEET' due to deleting URL's\n",
    "        \n",
    "for i in range(1, len(words)):\n",
    "    if not (words[i] == \"NEWTWEET\" and words[i] == words[i-1]):\n",
    "        cleaned_words_no_repeat.append(words[i])\n",
    "        \n",
    "words = cleaned_words_no_repeat\n",
    "# print(words)\n",
    "# print(words.index(\"and\"))\n",
    "words = np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "# Initialize states with start and end states (assuming no word is 'S' or 'E')\n",
    "states = ['S', 'E']\n",
    "for word in words:\n",
    "    if word not in states and word != \"\" and word != \"NEWTWEET\":\n",
    "        states.append(word)\n",
    "G.add_nodes_from(states)\n",
    "# nx.draw(G, with_labels = True)\n",
    "# print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = {}\n",
    "edges = []\n",
    "\n",
    "# Edge case for first word in tweet not being connected to Start state\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    if words[i] == \"NEWTWEET\":\n",
    "        edges.append(('S', words[i + 1], 1))\n",
    "        continue\n",
    "    elif words[i+1] == \"NEWTWEET\":\n",
    "        edges.append((words[i], 'E', 1))\n",
    "        continue\n",
    "    elif (words[i], words[i+1]) in freq:\n",
    "        freq[(words[i], words[i+1])] += 1\n",
    "    else:\n",
    "        freq[(words[i], words[i+1])] = 1\n",
    "        \n",
    "    if words[i].endswith(('.', '!', '?')):\n",
    "        edges.append((words[i], 'E', 1))\n",
    "        edges.append(('S', words[i + 1], 1))\n",
    "        \n",
    "edges.append(('E', 'S', 1))\n",
    "\n",
    "for edge in freq:\n",
    "    edges.append((edge[0], edge[1], freq[edge]))\n",
    "    \n",
    "G.add_weighted_edges_from(edges)\n",
    "# nx.draw(G, with_labels = True)\n",
    "# nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(list(G.successors('S')))\n",
    "# print(list(G.predecessors('E')))\n",
    "\n",
    "# print(list(G.predecessors('S')))\n",
    "# print(list(G.successors('E')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates numpy adjacency matrix of states, where Starting node is row 0 and Ending node is row 1\n",
    "matrix = nx.to_numpy_matrix(G, nodelist = states)\n",
    "matrix = np.array(matrix).tolist()\n",
    "# print(matrix)\n",
    "# print(np.array(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to see if adjacency matrix reflects actual state of MC\n",
    "num = 0\n",
    "for i in range(len(matrix[0])):\n",
    "    num += matrix[1][i]\n",
    "print(num == len(list(G.successors('E')))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(matrix)):\n",
    "    if np.array(matrix[i]).sum(axis=0) != 0:\n",
    "        continue\n",
    "    else:\n",
    "        print(i, np.array(matrix[i]).sum(axis=0))\n",
    "        print('broken state: ' + states[i])\n",
    "        print(list(G.predecessors(states[i])))\n",
    "\n",
    "matrix = np.delete(matrix, len(matrix)-1, axis=1)\n",
    "matrix = np.delete(matrix, len(matrix)-1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array(matrix)\n",
    "\n",
    "transition_mat = np.array(matrix)/np.array(matrix).sum(axis=1)[:,None]\n",
    "\n",
    "def get_next_state(i, transition_matrix):\n",
    "    return np.random.choice(transition_matrix.shape[1], 1, p=transition_matrix[i])[0]\n",
    "\n",
    "def perform_random_walk(s, e, transition_matrix):\n",
    "    curr_state = s\n",
    "    l = []\n",
    "    while curr_state != e:\n",
    "        curr_state = get_next_state(curr_state, transition_matrix)\n",
    "        if curr_state != s:\n",
    "            l.append(curr_state)\n",
    "    return np.array(l)\n",
    "\n",
    "def generate_sentence():\n",
    "    return ''.join([states[i] + ' ' for i in perform_random_walk(0, 1, transition_mat) if i != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of former President Trump's approval rate will lose $1.50 on the Unthinkable, and even knew this is no effective border laws work, not happy. \n"
     ]
    }
   ],
   "source": [
    "tweet = generate_sentence()\n",
    "if tweet.endswith('..'):\n",
    "    tweet += ' ' + generate(sentence)\n",
    "elif tweet.startswith('..'):\n",
    "    tweet = generate_sentence() + ' ' + tweet\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def guided_generation(w1, w2):\n",
    "    \"\"\"\n",
    "    Choose w1, w2 such that they are in the data set\n",
    "    \"\"\"\n",
    "    start = [states[i] + ' ' for i in perform_random_walk(0, w1, transition_mat) if i != 1]\n",
    "    middle = [states[i] + ' ' for i in perform_random_walk(w1, w2, transition_mat) if i != 1]\n",
    "    end = [states[i] + ' ' for i in perform_random_walk(w2, 1 transition_mat) if i != 1]\n",
    "    \n",
    "    return ''.join(start + middle[1:] + end[1:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(list(G.predecessors('and')))\n",
    "# print(list(G.successors('and')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
